\documentclass[11pt]{article}
\usepackage{fullpage,amsmath,amsfonts,graphicx,amsthm}
\usepackage{setspace}
\title{Data Application}
\author{Brianna C. Heggeseth}

\newtheorem{theorem}{Theorem}
  \newcommand{\B}[0]{\mathbf}
    \newcommand{\bs}[0]{\boldsymbol}

\begin{document}
\doublespace
\maketitle

Data Section 

Obesity has become one of the most burdensome public health issues of the time in the United States (cite surgeon general's report).  This epidemic has impacted children as well as adults.  A study estimates that about 32\% of children in the U.S. are overweight or obese (cite Ogden, Carroll, and Flegal 2008). There has been a push to encourage healthy diets and physical activity through increased education and community involvement with limited success. However, the available food and culture of physical exercise is society-based and will take time to fully change. It is generally accepted that the combination of genetic, metabolic, behavioral, and environmental factors play a role in children's weight. Yet, the exact determinants of childhood obesity is poorly understood.\\

Researchers hypothesize is that exposure to hormone-altering chemicals may disrupt and reprogram the metabolical system to favor weight gain (cite Tuma 2007). Animal studies suggest that endocrine disrupters such as bisphenal A and DDE cause increased weight after adjusting for exercise and amount and type of food (cite Tuma 2007/another reference), but in human studies, there are only moderately significant associations found (cite Mendez 2011).\\
 
 To fully understand the potential impact of chemical exposure on childhood growth development, it is necessary to observe weight and length/height of children over the time between infancy and adolescence. Quality longitudinal studies are starting to appear, but most of analyses do not take advantage of the longitudinal nature and only look two cross-sectional points to determine change. More recently, researchers have noted the important of the entire growth trajectory of individuals and attempt to group children with similar trajectory patterns (cite Pryor et al 2011, li et al 2007, Carter et al 2012, Garden 2012). \\

\section{Body Mass Index Trajectories}
Quantifying and evaluating children's growth is important task that involves measuring both weight and height. Body mass index (BMI), calculated as weight (kg)/height (m) squared, is a weight-height index that in effect is a method of adjust weight for height (cite Benn 1971). It is recommended as an indicator of total body fat for most individuals (Roche, Sievogel, Chulea, Webb 1981). The Center for Disease Control (CDC) publishes clinical charts that include reference growth curves for BMI-for-age in terms of percentiles or BMI z-scores using pooled BMI data from cross-sectional National Health and Nutrition Examination Survey data (NHANES). These curves are not intended for longitudinal analysis as the CDC performs different normalizing transformations for each month to resolve the skewed sex and age-specific distributions for BMI. Since the reference data is cross-sectional, the charts may not reflect typical age-related patterns of BMI change. Therefore, we concentrate on the raw BMI trajectories instead of BMI z-scores over time.\\ 

Researchers hypothesize that there are distinct growth patterns amongst children in the United States. Cluster analysis methods are applied to BMI trajectory data to discover data-driven groups based only on the growth measures and then additional analysis is done to estimate the relationship between maternal and early life factors and group membership (cite Pryor et al 2011, Li et al 2007, Carter et al 2012, Garden 2012).  Early life factors such as maternal BMI, maternal smoking, maternal weight gain, maternal age, birth weight, and duration of breastfeeding have been suggested to be potential predictors of increased risk of a high-rising BMI growth as well as the early and late onset of obesity.

\section{Clustering Analysis}
The clustering methods used in many longitudinal applications including body mass index trajectories are typically based on a finite mixture model, which is a probabilistic model for representing subgroups within the overall population that occur with different frequencies but are not known a priori. In the simplest form, the mixture density for the random outcome vector is a weighted sum of the subgroup densities
$$f(\B y|\bs\theta) = \sum^{K}_{k=1}P(C=k)P(\B Y=\B y|C=k) = \sum^{K}_{k=1}\pi_{k}f_{k}(\B y|\bs\theta_{k})$$
where $\pi_{k}$ is the probability of belonging to the $k$th group ($C$) and $\pi_{k}>0$ for all $k=1,..,K$ and $\sum^{K}_{k=1}\pi_{k}=1$. The probability densities, $f_{k}$ are assumed to be multivariate Gaussian for continuous outcomes such as BMI. With longitudinal data, the main goal is to study the change over time so typically the density for the data will also be conditional on the observations times, $\B t$, such that $$P(\B Y =\B y |C=k,\B T = \B t).$$
This model is the basis for many popular methods and software that have rapidly become commonplace in the growth trajectory literature.\\

The Proc Traj add-on package for SAS, used frequently in the BMI literature (cite Pryor 2011, Carater 2012) , fits group-based trajectory models such that for a continuous outcome measure, the subgroup distributions are assumed to be multivariate Gaussian with a polynomial mean such that the repeated measures within an individual are independent conditional on the group membership. Thus, the likelihood of observing the outcome data $\B y_{i} = (y_{i1},...,y_{im_{i}})$ for subject $i$ at times $\B t_{i} = (t_{i1},t_{i2},...,t_{im_{i}})$, given they belong to group $k$, is
$$P(\B Y_{i} = \B y_{i}|C_{i}=k,\B T_{i}=\B t_{i})\sim N(\bs\mu_{ik},\sigma^{2}I)$$
where $\bs\mu_{ik} = (\mu_{i1k},...,\mu_{im_{i}k})$ and $\mu_{ijk} = \beta_{0k}+\beta_{1k} t_{ij} + \beta_{2k}t_{ij}^{2}+ \beta_{3k} t_{ij}^{3}$. Additionally, the group probabilities can be modeled using a generalized logit function that allows time-stable covariates, $\B z_{i}$, determine group membership (setting $\bs\gamma_{K}=0$ for identifiability),
$$P(C_{i}=k|\B Z_{i}=\B z_{i}) = \frac{\exp(\bs\gamma_{k}^{T}\B z^{*}_{i})}{\sum^{K}_{l=1}\exp(\bs\gamma_{l}^{T}\B z^{*}_{i})}$$
where $\B z^{*}_{i} $ includes an intercept term appended to the vector of covariates. \\

Another software program, Mplus, commonly used in the literature (cite li et  al 2007, Garden 2012), fits a generalization of this model, termed a Growth Mixture Model, which allows random effects in the mean structure to account for within-class variation that is ignored in Proc Traj specification by assuming conditional independence. Assuming a distribution for the cluster-specific slope and intercept coefficients attempts to model within-individual covariance that is inherent in repeated measures. Thus the likelihood for the observed data for subject $i$ is
$$P(\B Y_{i} = \B y_{i}|C_{i}=k,\B T_{i}=\B t_{i})\sim N(\bs\mu_{ik},\bs\Sigma_{ik})$$
where the mean vector, $\bs\mu_{ik}$, can be defined in a similar manner as to Proc Traj, but the covariance matrix becomes dependent on the polynomial basis of time, $\bs\Sigma_{ik}=\Lambda_{i}\Psi_{k}\Lambda_{i}^{T}+\Theta_{k}$, where $\Theta_{k}$ is the covariance matrix of the random errors, $\Psi_{K}$ is the covariance matrix for the random effects, and $$\Lambda_{i}=\left(\begin{array}{cccc}1&t_{i1}&t_{i1}^{2}&t_{i1}^{3}\\ 1&\vdots&\vdots&\vdots\\ 1&t_{im_{i}}&t_{im_{i}}^{2}&t_{im_{i}}^{3}\\  \end{array} \right)$$
This specification is general enough to include Proc Traj specification by letting $\Psi_{k}=\B 0$ and $\Theta_{k}=\sigma^{2}I$ for all $k=1,...,K$. However, including random effects indirectly specifies a complex, non-stationary covariance structure, an assumption that is hard to check. This is problematic since misspecifying the covariance structure in finite multivariate Gaussian mixture models can cause bias in the mean estimates and an incorrect number of chosen groups (cite Heggeseth and Jewell 2013). The authors recommend fitting a model using an well known, stationary correlation structure such as exchangeable or exponential correlation before jumping to something more complex and non-stationary. Special attention should be paid to modeling the dependence inherent in repeated measures of an outcome over time.\\

These two model-based methods are typically understood to group individuals such that members of the same group share a similar pattern of change over time (cite Garden 2012). This suggests that two individuals with similar patterns of change but different vertical levels would be grouped together. However, model parameters and subsequently group membership are estimated by maximizing a likelihood function which is based on the Euclidean distance between observed data and the mean vectors if normality is assumed [Include graphs groups from mixture and as generated toy]. This process results in groups being primarily determined by the level despite subtle differences in the shape especially if the level and shape of a trajectory are independent or weakly dependent. Therefore, these methods as they are do not directly group trajectories on shape and resulting groups may include trajectories of the same level but different shapes over time. This translates into estimated group memberships and means not accurately representing the shape groups present in the data.\\

Due to this misunderstanding, researchers present the results of a mixture model analysis by discussing the shape of the estimated mean trajectories for each group (cite Pryor and Carter) However, the mean only represents the average shape of all trajectories in that group; not everyone, perhaps no one, follows the path of the mean especially when the groups are not homogeneous in terms of shape. Additionally, the estimated relationships between risk factors and the resulting groups are deceitful values given the group descriptions can be inaccurate. Care needs to be taken when making conclusions based on these methods especially in describing the shape of the trajectories within each group.  \\

Given the clear goals of these papers were to group individuals on the basis of the shape of their growth trajectory, it is appropriate to compare the new methods proposed in this thesis (eventually cite a methods paper). Vertically Shifting Mixture Models are based on the same foundation as those described above. The main differences is that rather than fitting a model to the raw data, the outcome is defined as the transformed or vertically shifted data vectors. Each individual's mean BMI is subtracted from all of their measured BMI values. In effect, each individual is normalized to have mean zero and the level is removed without eliminating the variability at each time point. By removing the mean prior to fitting a multivariate Gaussian mixture model with an exponential correlation structure, we allow the clustering method to focus directly on the shape rather than the level. Thus, the resulting groups can be honestly summarized by describing the shape of the mean trajectory of the group and estimated associations with risk factors can be interpreted accurately in terms of shape groups. We illustrate these cautions with BMI data on a group of Hispanic children.

\section{CHAMACOS}
The Center for the Health Assessment of Mothers and Children of Salinas (CHAMACOS) study is a longitudinal birth cohort designed to assess the health effects of pesticides and other environmental exposures on the growth and development in children living in the agricultural Salinas Valley, CA \cite{eskenazi2004,eskenazi2005}. Pregnant women were recruited in 1999-2000 in prenatal clinics, with 528 mother-child pairs in the study at delivery and 327 pairs remaining at the 9-year visit. Baseline maternal characteristics such as height and weight were measured at the start of the study and maternal urine and blood samples were taken twice during pregnancy and then again at delivery to measure levels of pesticide and chemical exposure. Child leptin levels were measured at interviews that occurred at birth and approximately 2 years, 5 years, and 9 years for a convenient sample of the children. For this paper, we limit our analysis to 80 children who have leptin levels available for all of the four time points. Details of the study are published elsewhere \cite{eskenazi2003}. All study activities were approved by the Committee for the Protection of Human Subjects at the University of California, Berkeley. \\

Leptin, a hormone synthesized primarily by adipose tissue but also by other major organs, acts on the hypothalamus to convey satiety and regulate long-term energy balance (cite Green 1995, Margetic 2022, Koerner 2005, Mantzoros 2001). High levels of leptin signal a sensation of being full and content, while low levels result in feelings of hunger and craving more food. Since the hormone is produced by adipose (fat) tissue, levels are proportion to amount of body fat; obese individuals have higher level of leptin, which is thought to cause leptin resistance and decreased sensitivity of the hypothalamus to changes in leptin levels. Very few studies have repeatedly measured leptin levels of individuals to study the change of leptin levels during early childhood, which is thought to be a critical obesity development period. In the cases in which more than one measurement is taken, leptin is observed at birth and then once more within a few years in an attempt to be able to predict leptin and adiposity levels at the later age. Characterizing leptin growth trajectories of children and whether there are distinct patterns is of great importance to public health officials since hormone levels are directly related to adiposity tissue and energy balance. We will use this data set to illustrate the differences between clustering methods and how they work in practice with real data sets.\\

\section{Methods}
More details for paper submission, but not for thesis?

\section{Results}

results for indep, exp, vertical. 


\section{Conclusion}
To explore the population in terms of their heterogenous growth patterns over time, we used multivariate finite mixture models. Rather than averaging out all of the interesting growth patterns, mixture models allows for a finite number of relationships. However, mixture models used 'right out of the box' finds these relationships based on the feature that dominate the variability. If this feature is the intercept or vertical level, the estimation of the mixture model may not highlight the patterns over time, which get lost in the groups based on the vertical level (cite my paper). Therefore, we use a simple adjustment to remove the vertical level and only focus on how the children's growth changes over time.\\\\



\begin{comment}

We use the standard and novel methods described in this thesis and compare the clustering results and the inference on baseline variables that may be related to cluster membership. First, as mentioned in the implementation sections of Chapter 4, we need to make decisions about the B-spline basis used in many of the methods. Figure \ref{fig:leptin} shows the original data. There are 80 lines corresponding to the four observed leptin levels for the 80 children in the data set. NOTE THAT INDIVIDUALS WERE NOT INTERVIEWED EXACTLY ON THEIR BIRTHDAY SO THERE IS VARIABILITY IN THE AGE OF INTERVIEWS WITHIN THE SAMPLE. ONE COULD MAKE THE ARGUMENT TO IGNORE THIS VARIABILITY AND COLLAPSE THE AGES OF INTERVIEWS IN MONTHS TO THE DESIRED AGE OF INTERVIEW IN YEARS SO THAT WE HAVE A VECTOR OF LENGTH 4 FOR EACH INDIVIDUAL. THE CHOICE OF THE TIME VARIABLE AFFECTS THE DEGREES OF FREEDOM THAT CAN BE USED IN THE BASIS SINCE IT IS LIMITED BY THE RANK OF THE DESIGN MATRIX OF BASIS VARIABLES. IF WE USE THE FOUR TIME POINTS, WE CAN ONLY HAVE AT MOST 4 DEGREES OF FREEDOM FOR THE BASIS SO THAT $X^{T}X$ IS INVERTIBLE. ON THE OTHER HAND, IF WE USE THE AGE AT INTERVIEWS, WE ARE NOT AS LIMITED IN THIS WAY. Based on the visual inspection of the data, we determine that quadratic curves with one knot should be sufficient to model the complexity given our data limitations. ONE PLACE OF DRASTIC CHANGE AND WE DON'T HAVE ENOUGH DATA POINTS PER INDIVIDUAL TO REALLY ESTIMATE A HIGHER ORDERED POLYNOMIAL CURVE WITHOUT EXTRAPOLATING QUITE A BIT BETWEEN POINTS.
\begin{figure}
\begin{center}
Figure with original data
\end{center}
\label{fig:leptin}
\caption{Logarithm of leptin measurements for 80 children in the CHAMACOS data observed at birth and approximately 2 years, 5 years, and 9 years of age. }
\end{figure}
Where to place the one internal knot. First, we can place it at the median time points. That forces a curvature to the later parts of the trajectory and forces the low point of the mean curve to be at the median, where we don't have any data. I would be better to have more smooth linear interpolation between the points so as to not extrapolate too much beyond the scope of the data. For both data sets, there is a drastic change in the shape that occurs at around the observation time of 24 months. This pulls the low point to the observe data and allows the rest of the curve to better fit the data.

Using the corresponding techniques to select the number of clusters, we perform all types of cluster analysis on the data set. 
GRAPHS FOR EACH METHOD
TABLE WITH ESTIMATES FOR KEY CONCOMITANT VARIABLES FOR EACH METHOD

\end{comment}




\end{document}